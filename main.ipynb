{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54b46404",
   "metadata": {},
   "source": [
    "# Let's start from the very beginning! ü§ì"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71009d1a",
   "metadata": {},
   "source": [
    "# <font color='0099cc'>Recommender Systems</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd56cf1",
   "metadata": {},
   "source": [
    "There are three main types of recommendation systems: collaborative filtering, content-based filtering ‚Äì and a hybrid of the two.\n",
    "\n",
    "<ul>\n",
    "    <font color='339966'><li><b> Collaborative filtering</b></li></font>\n",
    "</ul>\n",
    "Collaborative filtering focuses on collecting and analyzing data on user behavior, activities, and preferences, to predict what a person will like, based on their similarity to other users.\n",
    "<font color='339966'><b>An advantage of collaborative filtering is that it doesn‚Äôt need to analyze or understand the content</b></font> (products, films, books). It simply picks items to recommend based on what they know about the user.\n",
    "<ul>\n",
    "    <font color='0099cc'><li><b>Content-based filtering</b></li></font>\n",
    "</ul>\n",
    "Content-based filtering works on the principle that if you like a particular item, you will also like this other item. To make recommendations, algorithms use a profile of the customer‚Äôs preferences and a description of an item (genre, product type, color, word length) to work out the similarity of items using cosine and Euclidean distances.  \n",
    "The downside of content-based filtering is that the system is limited to recommending products or content similar to what the person is already buying or using.\n",
    "<ul>\n",
    "    <font color='0099cc'><li><b>Hybrid model</b></li></font>\n",
    "</ul>\n",
    "A hybrid recommendation engine looks at both the meta (collaborative) data and the transactional (content-based) data. Because of this, it outperforms both. \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec0d1f2",
   "metadata": {},
   "source": [
    "# <font color='0099cc'> &#8594; Collaborative filtering</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b95dda",
   "metadata": {},
   "source": [
    "The two primary areas of collaborative filtering are the neighborhood methods and latent factor models. \n",
    "<ul>\n",
    "    <font color='0099cc'><li><b>Neighborhood methods</b></li></font>\n",
    "</ul>\n",
    "These methods are centered on computing the relationships between items or, alternatively, between users.For example, To predict a particular user‚Äôs rating for Saving Private Ryan, we would look for the movie‚Äôs nearest neighbors that this user actually rated.\n",
    "<ul>\n",
    "    <font color='339966'><li><b>Latent factor models</b></li></font>\n",
    "</ul>\n",
    "These models are an alternative approach that tries to explain the ratings by characterizing both items and users on, say, 20 to 100 factors inferred from the ratings patterns.For movies, the discovered factors might measure dimensions such as comedy versus drama, amount of action, or orientation to children.For users, each factor measures how much the user likes movies that score high on the corresponding movie factor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36314b16",
   "metadata": {},
   "source": [
    "# <font color='0099cc'> &#8594; &#8594; Latent factor models</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad28fe28",
   "metadata": {},
   "source": [
    "Some of the most successful realizations of latent factor models are based on <font color='339966'><b>matrix factorization</b></font>. In its basic form, matrix factorization characterizes both items and users by vectors of factors inferred from item rating patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aba748d",
   "metadata": {},
   "source": [
    "# <font color='C02F1D'>  üëá Papers used in the next sections</font> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c239d139",
   "metadata": {},
   "source": [
    "[Matrix factorization techniques for recommender systems](https://www.inf.unibz.it/~ricci/ISR/papers/ieeecomputer.pdf) <br>Y Koren, R Bell, C Volinsky <br>- Computer, <font color='C02F1D'>2009</font>  <br>- ieeexplore.ieee.org<br>\n",
    "\n",
    "[Neural collaborative filtering](https://arxiv.org/pdf/1708.05031.pdf?source=post_page---------------------------)<br>\n",
    "X He, L Liao, H Zhang, L Nie, X Hu‚Ä¶ <br>- Proceedings of the 26th ‚Ä¶, <font color='C02F1D'>2017</font>  <br>- dl.acm.org<br>\n",
    "\n",
    "[Neural graph collaborative filtering](https://arxiv.org/pdf/1905.08108)<br>\n",
    "X Wang, X He, M Wang, F Feng, TS Chua <br>- Proceedings of the 42nd ‚Ä¶, <font color='C02F1D'>2019</font><br> - dl.acm.org<br>\n",
    "\n",
    "<font color='C02F1D'>The main one :</font><br> \n",
    "[Lightgcn: Simplifying and powering graph convolution network for recommendation](https://arxiv.org/pdf/2002.02126)\n",
    "X He, K Deng, X Wang, Y Li, Y Zhang‚Ä¶ <br>- Proceedings of the 43rd ‚Ä¶, <font color='C02F1D'>2020</font><br> - dl.acm.org"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca0cdfd4",
   "metadata": {},
   "source": [
    "# <font color='0099cc'> &#8594; &#8594; &#8594; A basic matrix fractorization model</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c31f82f5",
   "metadata": {},
   "source": [
    "Matrix factorization models map both users and items to a joint latent factor space of dimensionality f, such that user-item interactions are modeled as inner products in that space."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217f92a6",
   "metadata": {},
   "source": [
    "<!-- <img src=\"https://miro.medium.com/max/5130/1*b4M7o7W8bfRRxdMxtFoVBQ.png\">-->\n",
    "<img src=\"https://miro.medium.com/max/2000/1*WrOoSr49lQs43auSsLlLdg.png\" width=\"600\" height=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f3e5b18",
   "metadata": {},
   "source": [
    "Essentially, each user and item is projected onto a latent space, represented by a latent vector. The more similar the two latent vectors are, the more related the corresponding users‚Äô preference. <font color='0099cc'><b>Since we factorize the utility matrix into the same latent space, we can measure the similarity of any two latent vectors with dot product.</b></font>. In fact, the prediction for each user/ item entry is computed by the dot product of the corresponding latent vectors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ada6b63",
   "metadata": {},
   "source": [
    "<img src = \"https://miro.medium.com/max/1400/1*zKp0s2AEph60fu8o8r7oQQ.png\" width=\"400\" height=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f2461c",
   "metadata": {},
   "source": [
    "However, the paper argued that dot product limits the expressiveness of user and item latent vectors. Let‚Äôs consider the following case."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f932e3d6",
   "metadata": {},
   "source": [
    "<img src = \"https://miro.medium.com/max/1124/1*IdeD0DdRxvxFF0mOPekQ7g.png\" width=\"200\" height=\"300\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6fe7ea5",
   "metadata": {},
   "source": [
    "Let S{x,y} denotes the similarity between user x and user y. By computing the cosine-similarity between users 1, 2, and 3, we know that S{2, 3} > S{1, 2} > S{1, 3}. Without loss of generality, we map the users onto a latent space of two dimensions as the following.\n",
    "Now, we take into account user 4. Comparing the similarity with the others, we obtain S{1,4} > S{3,4} > S{2,4}. However, <font color='339966'><b>no matter we place the latent vector P4 to the right or left of P1, it will inevitably be closer to P2 than P3.</b></font>üòï"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e71fcc55",
   "metadata": {},
   "source": [
    "<img src = \"https://miro.medium.com/max/1400/1*7-I_MDs3aRE_rzwuj6J64A.png\" width=\"200\" height=\"300\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7915e767",
   "metadata": {},
   "source": [
    "The above example shows the possible limitation of MF caused by the use of a simple inner product to estimate complex user-item interactions in the low-dimensional latent space.<font color='339966'><b>Neural Collaborative Filtering</b></font> can address the limitation by learning the interaction function using DNNs from data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ee9836",
   "metadata": {},
   "source": [
    "# <font color='0099cc'> &#8594; &#8594; &#8594; Neural Collaborative Filtering</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c18686c",
   "metadata": {},
   "source": [
    "Since this work focuses on the pure collaborative filtering setting, we use only the identity of a user and an item as the input feature, <font color='0099cc'><b> transforming it to a binarized sparse vector with one-hot encoding</b></font> .\n",
    "Above the input layer is the embedding layer; it is a fully connected layer that projects the sparse representation to\n",
    "a dense vector. The obtained user (item) embedding can be seen as the latent vector for user (item) in the context of latent factor model. The user embedding and item embedding are then fed into a multi-layer neural architecture, which we term as neural collaborative filtering layers, to map the latent vectors to prediction scores."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc30600e",
   "metadata": {},
   "source": [
    "<img src = \"https://miro.medium.com/max/1400/1*sTBtqrsQzTKlZ8hSU7I6FQ.png\" width=\"400\" height=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b5d58c5",
   "metadata": {},
   "source": [
    "These methods are not sufficient to yield satisfactory embeddings for CF.üòï<br><font color='339966'><b>The key reason is that the embedding function lacks an explicit encoding of the crucial collaborative signal, which is latent in user-item interactions to reveal the behavioral similarity between users (or items)</b></font>.\n",
    "Look at this example :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19dee462",
   "metadata": {},
   "source": [
    "<img src = \"https://d3i71xaburhd42.cloudfront.net/c5f5f179d80a3bf9b4f29750283a87eaca42e91b/2-Figure1-1.png\" width=\"400\" height=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548bfc5a",
   "metadata": {},
   "source": [
    "The user of interest for recommendation is u1, labeled with the double circle in the left subfigure of user-item interaction\n",
    "graph. The right subfigure shows<br> the tree structure that is expanded from u1. The high-order connectivity denotes the path that reaches u1 from any node with the path length l larger than 1. <br>\n",
    "Such highorderconnectivity contains rich semantics that carry collaborative signal. <br>For example, the path u1 ‚Üêi2 ‚Üêu2 indicates the behavior similarity between u1 and u2, as both users have interacted with\n",
    "i2; the longer path u1 ‚Üêi2 ‚Üêu2 ‚Üêi4 suggests that u1 is likely to adopt i4, since her similar useru2 has consumed i4 before. Moreover, from the holistic view of l = 3, item i4 is more likely to be of interest\n",
    "to u1 than item i5, since there are two paths connecting <i4,u1>,while only one path connects <i5,u1>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e3b605",
   "metadata": {},
   "source": [
    "# <font color='0099cc'> &#8594; &#8594; &#8594; Neural Graph Collaborative Filtering</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06219b01",
   "metadata": {},
   "source": [
    "<img src=\"https://miro.medium.com/max/1400/1*6cBxhbNs9acjejFvsiqXMw.png\" width=\"500\" height=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c130e3",
   "metadata": {},
   "source": [
    "We propose to model the high-order connectivity information in the embedding function. Instead of expanding the interaction graph as a tree which is complex to implement, we design a neural network method to propagate embeddings\n",
    "recursively on the graph. This is inspired by the recent\n",
    "developments of <font color='0099cc'><b>graph neural networks</b></font>.ü•≥<br>Specifically, we devise an embedding propagation layer, which refines a user‚Äôs (or an item‚Äôs) embedding by aggregating the embeddings of the interacted items (or users). By stacking multiple embedding propagation layers, we can enforce the embeddings to capture the collaborative signal in high-order connectivities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f692231c",
   "metadata": {},
   "source": [
    "<ul>\n",
    "    <font color='0099cc'><li><b> Message Construction</b></li></font>\n",
    "</ul>\n",
    "for a connected user-item pair (u, i), we define the message from i to u as:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c1578df",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.discordapp.com/attachments/700393565699833936/935544467434381322/unknown.png\" height =200 width=300>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ea9241",
   "metadata": {},
   "source": [
    "<ul>\n",
    "    <font color='0099cc'><li><b> Message Aggregation</b></li></font>\n",
    "</ul>we aggregate the messages\n",
    "propagated from u‚Äôs neighborhood to refine u‚Äôs representation.\n",
    "Specifically, we define the aggregation function as:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2aee3d6",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.discordapp.com/attachments/700393565699833936/935546612242063390/unknown.png\" height =200 width=300>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a74d2ef",
   "metadata": {},
   "source": [
    "<i>The activation function of LeakyReLU allows messages to encode both positive and small negative signals.</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccacb5bc",
   "metadata": {},
   "source": [
    "# <font color='0099cc'> &#8594; &#8594; &#8594; Can we make NGCF better ? ü§î</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87469a8f",
   "metadata": {},
   "source": [
    "NGCF largely follows the standard GCN, <font color='C02F1D'><b>including the use\n",
    "of nonlinear activation function œÉ(¬∑) and feature transformation\n",
    "matrices W1 and W2. However, we argue that the two operations\n",
    "are not as useful for collaborative filtering</b></font>. In semi-supervised\n",
    "node classification, each node has rich semantic features as input,\n",
    "such as the title and abstract words of a paper. Thus performing\n",
    "multiple layers of nonlinear transformation is beneficial to feature\n",
    "learning. Nevertheless, in collaborative filtering, each node of useritem\n",
    "interaction graph only has an <font color='C02F1D'><b>ID as input which has no\n",
    "concrete semantics</b></font>. In this case, performing multiple nonlinear\n",
    "transformations will not contribute to learn better features; even\n",
    "worse, it may add the difficulties to train well. In the next subsection,\n",
    "we provide empirical evidence on this argument."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d068e2d",
   "metadata": {},
   "source": [
    "We perform ablation studies on NGCF to judge the usefulness of each operation in NGCF. The novel contribution of this section is to show that the two common designs in GCNs, feature transformation and nonlinear activation,\n",
    "have no positive effect on collaborative filtering.<br>We implement three simplified variants of NGCF:<br>\n",
    "<ul>\n",
    "    <font color='0099cc'><li><b> NGCF-f</b></li></font>\n",
    "</ul>\n",
    "which removes the feature transformation matrices W1 andW2.\n",
    "<ul>\n",
    "    <font color='0099cc'><li><b> NGCF-n</b></li></font>\n",
    "</ul>\n",
    "which removes the non-linear activation function œÉ.\n",
    "<ul>\n",
    "    <font color='0099cc'><li><b> NGCF-fn</b></li></font>\n",
    "</ul>\n",
    "which removes both the feature transformation matrices and non-linear activation function.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd284cb",
   "metadata": {},
   "source": [
    "We plot the curves of model status recorded by training loss and testing\n",
    "recall in Figure 1.\n",
    "As can be seen,<font color='0099cc'><b> NGCF-fn achieves a much lower\n",
    "training loss than NGCF, NGCF-f, and NGCF-n</b></font>  along the whole\n",
    "training process. Aligning with the curves of testing recall, we\n",
    "find that such lower training loss successfully transfers to better\n",
    "recommendation accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a9282ec",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.discordapp.com/attachments/700393565699833936/935601922763816970/unknown.png\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "424b2357",
   "metadata": {},
   "source": [
    "From these evidences, we can draw the conclusion that the deterioration of NGCF stems from the training difficulty,\n",
    "rather than overfitting.\n",
    "In this section, we first present our designed <font color='339966'><b> Light Graph Convolution Network (LightGCN) model</b></font>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e744ce3",
   "metadata": {},
   "source": [
    "# <font color='0099cc'> &#8594; &#8594; &#8594; LightGCN üîÆ </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0711448e",
   "metadata": {},
   "source": [
    "In Light Graph Convolution, only the normalized sum of neighbor embeddings is performed towards next layer; other operations like self-connection, feature transformation, and nonlinear activation are all removed, which largely simplifies GCNs. In Layer Combination, we sum over the embeddings at each layer to obtain the final representations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af29f93",
   "metadata": {},
   "source": [
    "<img src=\"https://recodatasets.z20.web.core.windows.net/images/lightGCN-model.jpg\" height = 500 width = 500>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a47a47",
   "metadata": {},
   "source": [
    "we adopt the simple weighted sum aggregator and abandon the use of feature transformation and nonlinear activation. <br>\n",
    "<ul>\n",
    "    <font color='0099cc'><li><b>The graph convolution operation in LightGCN is defined as:</b></li></font>\n",
    "</ul>\n",
    "\n",
    "$$\n",
    "\\begin{array}{l}\n",
    "\\mathbf{e}_{u}^{(k+1)}=\\sum_{i \\in \\mathcal{N}_{u}} \\frac{1}{\\sqrt{\\left|\\mathcal{N}_{u}\\right|} \\sqrt{\\left|\\mathcal{N}_{i}\\right|}} \\mathbf{e}_{i}^{(k)} \\\\\n",
    "\\mathbf{e}_{i}^{(k+1)}=\\sum_{u \\in \\mathcal{N}_{i}} \\frac{1}{\\sqrt{\\left|\\mathcal{N}_{i}\\right|} \\sqrt{\\left|\\mathcal{N}_{u}\\right|}} \\mathbf{e}_{u}^{(k)}\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "the symmetric normalization term $\\frac{1}{\\sqrt{\\left|\\mathcal{N}_{u}\\right|} \\sqrt{\\left|\\mathcal{N}_{i}\\right|}}$ follows the design of standard GCN, which can avoid the scale of embeddings increasing with graph convolution operations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746bfd63",
   "metadata": {},
   "source": [
    "<ul>\n",
    "    <font color='0099cc'><li><b>Layer Combination and Model Prediction</b></li></font>\n",
    "</ul>\n",
    "the only trainable model parameters are the embeddings at the 0-th layer, i.e., $\\mathbf{e}_{u}^{(0)}$ for all users and $\\mathbf{e}_{i}^{(0)}$ for all items. When they are given, the embeddings at higher layers can be computed via LGC. After $K$ layers LGC, we further combine the embeddings obtained at each layer to form the final representation of a user (an item):\n",
    "\n",
    "$$\n",
    "\\mathbf{e}_{u}=\\sum_{k=0}^{K} \\alpha_{k} \\mathbf{e}_{u}^{(k)} ; \\quad \\mathbf{e}_{i}=\\sum_{k=0}^{K} \\alpha_{k} \\mathbf{e}_{i}^{(k)}\n",
    "$$\n",
    "\n",
    "where $\\alpha_{k} \\geq 0$ denotes the importance of the $k$-th layer embedding in constituting the final embedding. In our experiments, we set $\\alpha_{k}$ uniformly as $1 / (K+1)$.\n",
    "\n",
    "The model prediction is defined as the inner product of user and item final representations:\n",
    "\n",
    "$$\n",
    "\\hat{y}_{u i}=\\mathbf{e}_{u}^{T} \\mathbf{e}_{i}\n",
    "$$\n",
    "\n",
    "which is used as the ranking score for recommendation generation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4442777",
   "metadata": {},
   "source": [
    "<ul>\n",
    "    <font color='0099cc'><li><b>Model Training</b></li></font>\n",
    "</ul>\n",
    "We employ the Bayesian Personalized Ranking (BPR) loss which is a pairwise loss that encourages the prediction of an observed entry to be higher than its unobserved counterparts:\n",
    "\n",
    "$$\n",
    "L_{B P R}=-\\sum_{u=1}^{M} \\sum_{i \\in \\mathcal{N}_{u}} \\sum_{j \\notin \\mathcal{N}_{u}} \\ln \\sigma\\left(\\hat{y}_{u i}-\\hat{y}_{u j}\\right)+\\lambda\\left\\|\\mathbf{E}^{(0)}\\right\\|^{2}\n",
    "$$\n",
    "\n",
    "Where $\\lambda$ controls the $L_2$ regularization strength. We employ the Adam optimizer and use it in a mini-batch manner."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3173de34",
   "metadata": {},
   "source": [
    "# <font color='0099cc'> &#8594; &#8594; &#8594; Movie Recommender Using LightGCN üíª</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fdfaa7c",
   "metadata": {},
   "source": [
    "We will use the MovieLens dataset, convert MovieLens into implicit feedback for model training and evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4cbbd00",
   "metadata": {},
   "source": [
    "### <font color='0099cc'> Imports</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b79bfdd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import papermill as pm\n",
    "import scrapbook as sb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "tf.get_logger().setLevel('ERROR') # only show error messages\n",
    "\n",
    "from recommenders.utils.timer import Timer\n",
    "from recommenders.models.deeprec.models.graphrec.lightgcn import LightGCN\n",
    "from recommenders.models.deeprec.DataModel.ImplicitCF import ImplicitCF\n",
    "from recommenders.datasets import movielens\n",
    "from recommenders.datasets.python_splitters import python_stratified_split\n",
    "from recommenders.evaluation.python_evaluation import map_at_k, ndcg_at_k, precision_at_k, recall_at_k\n",
    "from recommenders.utils.constants import SEED as DEFAULT_SEED\n",
    "from recommenders.models.deeprec.deeprec_utils import prepare_hparams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6dab27",
   "metadata": {},
   "source": [
    "### <font color='0099cc'>  Defining Parameters</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d9ab4174",
   "metadata": {},
   "outputs": [],
   "source": [
    "# top k items to recommend\n",
    "TOP_K = 10\n",
    "\n",
    "# Select MovieLens data size: 100k, 1m, 10m, or 20m\n",
    "MOVIELENS_DATA_SIZE = '100k'\n",
    "\n",
    "# Model parameters\n",
    "EPOCHS = 50\n",
    "BATCH_SIZE = 1024\n",
    "\n",
    "SEED = DEFAULT_SEED  # Set None for non-deterministic results\n",
    "\n",
    "yaml_file = \"./recommenders/models/deeprec/config/lightgcn.yaml\"\n",
    "user_file = \"./tests/resources/deeprec/lightgcn/user_embeddings.csv\"\n",
    "item_file = \"./tests/resources/deeprec/lightgcn/item_embeddings.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ad6b89",
   "metadata": {},
   "source": [
    "### <font color='0099cc'>  Loading Data</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "77681c0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4.81k/4.81k [00:03<00:00, 1.33kKB/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>itemID</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3.0</td>\n",
       "      <td>881250949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3.0</td>\n",
       "      <td>891717742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "      <td>1.0</td>\n",
       "      <td>878887116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>244</td>\n",
       "      <td>51</td>\n",
       "      <td>2.0</td>\n",
       "      <td>880606923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166</td>\n",
       "      <td>346</td>\n",
       "      <td>1.0</td>\n",
       "      <td>886397596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userID  itemID  rating  timestamp\n",
       "0     196     242     3.0  881250949\n",
       "1     186     302     3.0  891717742\n",
       "2      22     377     1.0  878887116\n",
       "3     244      51     2.0  880606923\n",
       "4     166     346     1.0  886397596"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = movielens.load_pandas_df(size=MOVIELENS_DATA_SIZE)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13bdedfd",
   "metadata": {},
   "source": [
    "### <font color='0099cc'>  Spliting the Dataset</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b0ff3cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = python_stratified_split(df, ratio=0.75)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ee4013",
   "metadata": {},
   "source": [
    "### <font color='0099cc'>  Processing the Dataset</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b06b29a9",
   "metadata": {},
   "source": [
    "`ImplicitCF` is a class that intializes and loads data for the training process. During the initialization of this class, user IDs and item IDs are reindexed, ratings greater than zero are converted into implicit positive interaction, and adjacency matrix $R$ of user-item graph is created. Some important methods of `ImplicitCF` are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2b88e452",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ImplicitCF(train=train, test=test, seed=SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e580d36c",
   "metadata": {},
   "source": [
    "### <font color='0099cc'>  Create and Train Model</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f57596b3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already create adjacency matrix.\n",
      "Already normalize adjacency matrix.\n",
      "Using xavier initialization.\n",
      "Epoch 1 (train)5.4s: train loss = 0.46985 = (mf)0.46960 + (embed)0.00025\n",
      "Epoch 2 (train)4.5s: train loss = 0.28470 = (mf)0.28405 + (embed)0.00066\n",
      "Epoch 3 (train)4.8s: train loss = 0.25343 = (mf)0.25260 + (embed)0.00082\n",
      "Epoch 4 (train)4.6s: train loss = 0.23669 = (mf)0.23570 + (embed)0.00099\n",
      "Epoch 5 (train)4.3s + (eval)0.5s: train loss = 0.23210 = (mf)0.23100 + (embed)0.00111, recall = 0.15584, ndcg = 0.34174, precision = 0.29703, map = 0.08969\n",
      "Epoch 6 (train)4.2s: train loss = 0.22394 = (mf)0.22274 + (embed)0.00120\n",
      "Epoch 7 (train)4.4s: train loss = 0.21258 = (mf)0.21126 + (embed)0.00132\n",
      "Epoch 8 (train)4.4s: train loss = 0.20166 = (mf)0.20020 + (embed)0.00146\n",
      "Epoch 9 (train)4.3s: train loss = 0.18874 = (mf)0.18712 + (embed)0.00161\n",
      "Epoch 10 (train)4.4s + (eval)0.3s: train loss = 0.18451 = (mf)0.18273 + (embed)0.00178, recall = 0.17787, ndcg = 0.38410, precision = 0.33521, map = 0.10577\n",
      "Epoch 11 (train)4.5s: train loss = 0.17410 = (mf)0.17217 + (embed)0.00193\n",
      "Epoch 12 (train)4.4s: train loss = 0.17040 = (mf)0.16833 + (embed)0.00207\n",
      "Epoch 13 (train)4.4s: train loss = 0.16702 = (mf)0.16483 + (embed)0.00219\n",
      "Epoch 14 (train)4.3s: train loss = 0.16283 = (mf)0.16052 + (embed)0.00231\n",
      "Epoch 15 (train)4.5s + (eval)0.2s: train loss = 0.16481 = (mf)0.16240 + (embed)0.00241, recall = 0.19029, ndcg = 0.40063, precision = 0.35239, map = 0.11369\n",
      "Epoch 16 (train)4.7s: train loss = 0.15999 = (mf)0.15750 + (embed)0.00249\n",
      "Epoch 17 (train)4.5s: train loss = 0.15837 = (mf)0.15578 + (embed)0.00259\n",
      "Epoch 18 (train)4.4s: train loss = 0.15713 = (mf)0.15445 + (embed)0.00268\n",
      "Epoch 19 (train)4.5s: train loss = 0.15482 = (mf)0.15205 + (embed)0.00277\n",
      "Epoch 20 (train)4.4s + (eval)0.2s: train loss = 0.15033 = (mf)0.14747 + (embed)0.00287, recall = 0.19798, ndcg = 0.42035, precision = 0.36681, map = 0.12280\n",
      "Epoch 21 (train)4.3s: train loss = 0.14697 = (mf)0.14400 + (embed)0.00297\n",
      "Epoch 22 (train)4.4s: train loss = 0.14643 = (mf)0.14335 + (embed)0.00308\n",
      "Epoch 23 (train)4.3s: train loss = 0.14328 = (mf)0.14009 + (embed)0.00319\n",
      "Epoch 24 (train)4.6s: train loss = 0.14280 = (mf)0.13952 + (embed)0.00329\n",
      "Epoch 25 (train)4.5s + (eval)0.3s: train loss = 0.13946 = (mf)0.13606 + (embed)0.00340, recall = 0.20415, ndcg = 0.43040, precision = 0.37911, map = 0.12765\n",
      "Epoch 26 (train)4.6s: train loss = 0.13822 = (mf)0.13470 + (embed)0.00352\n",
      "Epoch 27 (train)4.5s: train loss = 0.13603 = (mf)0.13241 + (embed)0.00362\n",
      "Epoch 28 (train)4.5s: train loss = 0.13417 = (mf)0.13043 + (embed)0.00374\n",
      "Epoch 29 (train)4.5s: train loss = 0.13272 = (mf)0.12887 + (embed)0.00385\n",
      "Epoch 30 (train)4.4s + (eval)0.2s: train loss = 0.12973 = (mf)0.12576 + (embed)0.00397, recall = 0.20664, ndcg = 0.43794, precision = 0.38335, map = 0.13047\n",
      "Epoch 31 (train)4.4s: train loss = 0.12582 = (mf)0.12172 + (embed)0.00410\n",
      "Epoch 32 (train)4.7s: train loss = 0.12529 = (mf)0.12107 + (embed)0.00422\n",
      "Epoch 33 (train)5.0s: train loss = 0.12473 = (mf)0.12039 + (embed)0.00433\n",
      "Epoch 34 (train)5.3s: train loss = 0.12055 = (mf)0.11609 + (embed)0.00446\n",
      "Epoch 35 (train)4.5s + (eval)0.2s: train loss = 0.11910 = (mf)0.11450 + (embed)0.00460, recall = 0.20874, ndcg = 0.44590, precision = 0.38897, map = 0.13442\n",
      "Epoch 36 (train)4.4s: train loss = 0.11901 = (mf)0.11431 + (embed)0.00471\n",
      "Epoch 37 (train)4.4s: train loss = 0.11939 = (mf)0.11457 + (embed)0.00482\n",
      "Epoch 38 (train)4.4s: train loss = 0.11475 = (mf)0.10980 + (embed)0.00495\n",
      "Epoch 39 (train)4.4s: train loss = 0.11329 = (mf)0.10821 + (embed)0.00508\n",
      "Epoch 40 (train)4.7s + (eval)0.2s: train loss = 0.11287 = (mf)0.10767 + (embed)0.00520, recall = 0.21201, ndcg = 0.45121, precision = 0.39618, map = 0.13574\n",
      "Epoch 41 (train)4.9s: train loss = 0.10988 = (mf)0.10457 + (embed)0.00531\n",
      "Epoch 42 (train)4.6s: train loss = 0.11133 = (mf)0.10588 + (embed)0.00545\n",
      "Epoch 43 (train)5.1s: train loss = 0.10687 = (mf)0.10132 + (embed)0.00555\n",
      "Epoch 44 (train)5.0s: train loss = 0.10525 = (mf)0.09957 + (embed)0.00569\n",
      "Epoch 45 (train)4.9s + (eval)0.3s: train loss = 0.10560 = (mf)0.09980 + (embed)0.00580, recall = 0.21415, ndcg = 0.45688, precision = 0.40244, map = 0.13700\n",
      "Epoch 46 (train)4.7s: train loss = 0.10427 = (mf)0.09834 + (embed)0.00593\n",
      "Epoch 47 (train)5.0s: train loss = 0.10053 = (mf)0.09447 + (embed)0.00606\n",
      "Epoch 48 (train)5.4s: train loss = 0.10109 = (mf)0.09488 + (embed)0.00620\n",
      "Epoch 49 (train)4.6s: train loss = 0.10005 = (mf)0.09373 + (embed)0.00631\n",
      "Epoch 50 (train)5.0s + (eval)0.3s: train loss = 0.10024 = (mf)0.09380 + (embed)0.00644, recall = 0.21348, ndcg = 0.45546, precision = 0.40042, map = 0.13574\n",
      "Took 232.78629109999747 seconds for training.\n"
     ]
    }
   ],
   "source": [
    "hparams = prepare_hparams(yaml_file,\n",
    "                          n_layers=3,\n",
    "                          batch_size=BATCH_SIZE,\n",
    "                          epochs=EPOCHS,\n",
    "                          learning_rate=0.005,\n",
    "                          eval_epoch=5,\n",
    "                          top_k=TOP_K,\n",
    "                         )\n",
    "\n",
    "model = LightGCN(hparams, data, seed=SEED)\n",
    "with Timer() as train_time:\n",
    "    model.fit()\n",
    "\n",
    "print(\"Took {} seconds for training.\".format(train_time.interval))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2904e223",
   "metadata": {},
   "source": [
    "### <font color='0099cc'>  Recommending</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2164572e",
   "metadata": {},
   "source": [
    "We can call recommend_k_items to recommend k items for each user passed in this function. We set remove_seen=True to remove the items already seen by the user. The function returns a dataframe, containing each user and top k items recommended to them and the corresponding ranking scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "63d2ab28",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>itemID</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>5.792505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>475</td>\n",
       "      <td>5.483119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>919</td>\n",
       "      <td>5.352049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>5.296583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5.276996</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userID  itemID  prediction\n",
       "0       1       7    5.792505\n",
       "1       1     475    5.483119\n",
       "2       1     919    5.352049\n",
       "3       1      89    5.296583\n",
       "4       1       1    5.276996"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topk_scores = model.recommend_k_items(test, top_k=TOP_K, remove_seen=True)\n",
    "\n",
    "topk_scores.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65945413",
   "metadata": {},
   "source": [
    "### <font color='0099cc'>  Evaluating</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "962590f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP:\t0.135738\n",
      "NDCG:\t0.455456\n",
      "Precision@K:\t0.400424\n",
      "Recall@K:\t0.213484\n"
     ]
    }
   ],
   "source": [
    "eval_map = map_at_k(test, topk_scores, k=TOP_K)\n",
    "eval_ndcg = ndcg_at_k(test, topk_scores, k=TOP_K)\n",
    "eval_precision = precision_at_k(test, topk_scores, k=TOP_K)\n",
    "eval_recall = recall_at_k(test, topk_scores, k=TOP_K)\n",
    "\n",
    "print(\"MAP:\\t%f\" % eval_map,\n",
    "      \"NDCG:\\t%f\" % eval_ndcg,\n",
    "      \"Precision@K:\\t%f\" % eval_precision,\n",
    "      \"Recall@K:\\t%f\" % eval_recall, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86130bef",
   "metadata": {},
   "source": [
    "# <font color='0099cc'>  Thankyou for bearing with us ! üòÑ\t</font>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
